{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAllo???\n",
    "# 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook purpose\n",
    "- Connect to Overpass API\n",
    "- Extract coordinates of all hiking trails within Switzerland\n",
    "- Convert data into a pandas dataframe object\n",
    "- Create a table in SQL database (hosted on Microsoft Azure)\n",
    "- Store coordinates in SQL DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overpy ist eine Python-Bibliothek, die es ermöglicht, Daten von der Overpass API (eine Schnittstelle für OpenStreetMap-Daten) abzufragen und zu verarbeiten. Die Overpass API ermöglicht es, Wanderwege aus dem OpenStreetMap-Projekt (OSM) abzurufen.\n",
    "\n",
    "Die Abrage sucht nach Wanderrouten in einem Giebiet welche mit spezifischen Signalisationen ausgeschildert sind. \n",
    "\n",
    "Falls das der Name nicht vorhanden ist, aber die Bezeichnungen von und bis existieren, wird der Name zusammengesetzt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sqlalchemy dient dazu, SQL-Datenbanken mit Python-Code zu verbinden und erleichtert das Arbeiten mit relationalen Datenbanken. sqlalchemy bietet einen direkten Zugriff auf SQL-Datenbanken, was Flexibilität ermöglicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd \n",
    "import overpy\n",
    "import json\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pymssql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisiere die Overpass API mit einer benutzerdefinierten URL\n",
    "api = overpy.Overpass(url=\"http://overpass.osm.ch/api/interpreter\")\n",
    "\n",
    "# Overpass Query für Wanderwege innerhalb der Schweiz. Mit Center erhalten wir die Koordinaten in der Mitte eines Wnaderweges\n",
    "query = \"\"\"\n",
    "[out:json];\n",
    "relation\n",
    "[\"route\"=\"hiking\"]\n",
    "/*[\"name\"]*/\n",
    "[\"name\"!~\"fixme\", i]\n",
    "[\"network\"=\"lwn\"]\n",
    "[\"osmc:symbol\"~\"yellow::yellow_diamond|red:white:red_bar|yellow:white:yellow_diamond|blue:white:blue_bar\"]\n",
    "/*(id: 1432463)*/\n",
    "(45.8899, 6.0872, 47.8085, 10.4921);\n",
    "out center tags;\n",
    "\"\"\"\n",
    "\n",
    "# Führe die Anfrage aus\n",
    "result = api.query(query)\n",
    "\n",
    "# Liste zum Speichern der extrahierten Informationen\n",
    "list = []\n",
    "\n",
    "# Iteration über alle relations\n",
    "for relation in result.relations:\n",
    "    \n",
    "    # Extrahiere die relevanten Daten\n",
    "\n",
    "    org_name = relation.tags.get('name')\n",
    "    fix_name = \"\"\n",
    "    org_to = relation.tags.get('to')\n",
    "    org_from = relation.tags.get('from')\n",
    "    \n",
    "    # Center ist ein Tupel mit langitute und longitude, wir möchten nur einen wert\n",
    "    lat = getattr(relation, 'center_lat')\n",
    "    lon = getattr(relation, 'center_lon')\n",
    "    \n",
    "    # Wenn der orginal Name nicht vorhanden ist setze ihn aus from und to zusammen\n",
    "    if not org_name and org_from and org_to :\n",
    "        fix_name = f\"{org_from} - {org_to}\"\n",
    "    else:\n",
    "        fix_name = org_name\n",
    "\n",
    "    # Erstelle ein Dictionary um die Attribute als Tupel zu speichern\n",
    "    if fix_name and lat > 0 and lon > 0: \n",
    "        dict = {\n",
    "        'id': relation.id,\n",
    "        'name': fix_name,\n",
    "        'lat': lat,\n",
    "        'lon': lon\n",
    "        }\n",
    "\n",
    "        # Jedes Tupel wird nun in der Liste als neue Zeile gespeichert\n",
    "        list.append(dict)\n",
    "\n",
    "# Wenn alle Daten verarbeitet wurden, erstelle das DataFrame\n",
    "df_wanderwege = pd.DataFrame(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15196 entries, 0 to 15195\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   timestamp_apicall  15196 non-null  object\n",
      " 1   id                 15196 non-null  int64 \n",
      " 2   name               15196 non-null  object\n",
      " 3   lat                15196 non-null  object\n",
      " 4   lon                15196 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 593.7+ KB\n",
      "None\n",
      "-----------------------------------------\n",
      "     timestamp_apicall      id                                          name  \\\n",
      "0  2024-09-20 10:53:34   22614  Nationalpark Wanderroute 15 (Munt la Schera)   \n",
      "1  2024-09-20 10:53:34  103607                                 Wanderwege SG   \n",
      "2  2024-09-20 10:53:34  112830                Uetliberg - Uetliberg Uto Kulm   \n",
      "3  2024-09-20 10:53:34  112831                           Folenweid - Baldern   \n",
      "4  2024-09-20 10:53:34  112833                          Felsenegg - Balderen   \n",
      "\n",
      "          lat         lon  \n",
      "0  46.6501430  10.2301992  \n",
      "1  47.4309774   9.6201700  \n",
      "2  47.3511680   8.4897796  \n",
      "3  47.3291235   8.5007261  \n",
      "4  47.3152439   8.5050559  \n"
     ]
    }
   ],
   "source": [
    "# Add time and datestamp of API call to dataframe\n",
    "df_wanderwege[\"timestamp_apicall\"] = pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Change column order and print dataframe\n",
    "col_order = ['timestamp_apicall', 'id', 'name', 'lat', 'lon']\n",
    "df_wanderwege = df_wanderwege[col_order]\n",
    "\n",
    "print(df_wanderwege.info())\n",
    "print(\"-----------------------------------------\")\n",
    "print(df_wanderwege.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\etien\\OneDrive\\02_Progression\\CAS_DataEngineering_ZHAW\\03_Leistungsnachweis\\Wanderwege\\notebooks\n"
     ]
    }
   ],
   "source": [
    "# Get current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# c:\\Users\\etien\\OneDrive\\02_Progression\\CAS_DataEngineering_ZHAW\\03_Leistungsnachweis\\Wanderwege\\notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load database access configuration from config/db_config.json\n",
    "with open('../config/db_config.json', 'r') as f:\n",
    "    db_config = json.load(f)\n",
    "\n",
    "# Access db credentials\n",
    "server = db_config['server']\n",
    "database = db_config['database']\n",
    "db_user = db_config['db_user']\n",
    "db_password = db_config['db_password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQL Database\n",
    "conn = pymssql.connect(server, db_user, db_password, database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection string for SQLAlchemy\n",
    "connection_string = f\"mssql+pymssql://{db_user}:{db_password}@{server}/{database}\"\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to SQL Database\n",
    "df_wanderwege.to_sql('wanderwege', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_sql_table(table_name='wanderwege', con=engine)\n",
    "print(df_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly close the engine's connection pool (not best practice -> add \"with engine.connect() as connection:\" instead)\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe use this function for multiple loads\n",
    "\"\"\" \n",
    "\n",
    "def load_data_to_sql(df, table_name, server, database, username, password):\n",
    "    # Build the connection string\n",
    "    connection_string = f\"DRIVER={{ODBC Driver 18 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password};Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
    "    \n",
    "    # Create the engine\n",
    "    params = urllib.parse.quote_plus(connection_string)\n",
    "    engine = create_engine(f'mssql+pyodbc:///?odbc_connect={params}')\n",
    "    \n",
    "    # Use inspector to check if the table exists\n",
    "    inspector = inspect(engine)\n",
    "    \n",
    "    # Check if the table exists in the database\n",
    "    if table_name in inspector.get_table_names():\n",
    "        print(f\"Table '{table_name}' exists. Appending data...\")\n",
    "        # Append the DataFrame to the existing table\n",
    "        df.to_sql(table_name, con=engine, if_exists='append', index=False)\n",
    "    else:\n",
    "        print(f\"Table '{table_name}' does not exist. Creating table and inserting data...\")\n",
    "        # Create the table and insert the data\n",
    "        df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "    \n",
    "    print(\"Data has been loaded successfully.\")\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example - Load DataFrame into MySQL Database\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Verbindung zur MySQL-Datenbank herstellen (ersetze Platzhalter mit deinen Daten)\n",
    "user = 'root'        # MySQL-Benutzername\n",
    "password = ''  # MySQL-Passwort\n",
    "host = '127.0.0.1'   # Server (bei lokalen Installationen ist das oft 'localhost')\n",
    "database = 'mydatabase'  # Name der Datenbank, in die du schreiben möchtest\n",
    "\n",
    "# Erstelle die Verbindungs-Engine\n",
    "engine = create_engine(f\"mysql+pymysql://{user}:{password}@{host}/{database}\")\n",
    "\n",
    "# DataFrame in die MySQL-Datenbank-Tabelle schreiben (wenn die Tabelle nicht existiert, wird sie erstellt)\n",
    "df.to_sql(name='Wanderwege', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"DataFrame erfolgreich in die MySQL-Datenbank geladen!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daengenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
